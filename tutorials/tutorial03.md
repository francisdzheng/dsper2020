---
layout: page
title: Bootstrap
parent: Tutorials
nav_exclude: true
---

# Bootstrap
{:.no_toc}

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## What is bootstrap?

Bootstrap is a method used for estimating a population parameter by repeatedly drawing distinct samples, with replacement, from the population. 

![bootstrap1](bootstrap1.png)

Image Source: [An Introduction to the Bootstrap Method](https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60)

> *The original sample approximates the population from which it was drawn. So resamples from this sample approximate what we would get if we took many samples from the population. The bootstrap distribution of a statistic, based on many resamples, approximates the sampling distribution of the statistic, based on many samples.*

> Source: Mathematical Statistics with Resampling and R Laura M. Chihara, ‎Tim C. Hesterberg - 2012

An example of bootstrapping measuring 


Please refer to the slides form Lecture 04](https://piazza.com/class_profile/get_resource/k8pcxfiwkxf2ec/k9jgjkfppry4vv) for more on bootstrap. 


## Importing Libraries

As usual, we will want to use `numpy`, `pandas`, `matplot`, and `seaborn` to help us manipulate and visualize our data. 

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```

## Our Data Set

For this example, I will use a hypothetical data set, so we won't be importing from any csv files. Let's say we conducted a study on the amount of 


## Bootstrapping for Linear Regression

In Homework 02, you fitted a linear regression model for your data.

INSERT EQUATION


Now, we would like to construct conﬁdence intervals for the estimated coefﬁcients and perhaps even infer the true coefficients of our model. Bootstrap is a computational method that allows us to calculate standard errors and confidence intervals for our parameters.


### Our Data Set

In this example, I'll be estimating the price of houses in [King County, Washington](https://en.wikipedia.org/wiki/King_County,_Washington). 

You can obtain the dataset [here](https://www.kaggle.com/harlfoxem/housesalesprediction).

There are 21 columns in this dataset, but for the purposes of this tutorial, we will just look at a couple. Let's look at the following parameters to estimate price:
- `sqft_living`: the size, in square feet, of the living area of the house
- `yr_built`: the year in which the house was built

After downloading, read our data using something like the following:

```python
df = pd.read_csv("kc_house_data.csv", usecols=["price", "sqft_living", "yr_built"])
```

### Visualizing Our Data

Before doing anything, let's get a little bit more familiar with our data. As we learned in Tutorial 02, first use `head()` to see the first five rows of our dataframe: 

```python
df.head()
```


|       | price | sqft_living | yr_built |
|:-----:|:------------:|:-----------:|:------------:|
| **0** |      221900.0    |     1180     |      1955     |
| **1** |      538000.0     |     2570     |      1951    |
| **2** |      180000.0    |     770     |      1933    |
| **3** |      604000.0     |     1960     |      1965     |
| **4** |      510000.0     |     1680     |      1987    | 


Let's also create scatter plots to visualize the relationships between our variables:

```python
plt.xlabel("sqft_living")
plt.ylabel("price")
plt.scatter(x=df["sqft_living"], y=df["price"])
```

![sqftbyprice](sqftbyprice.svg)


```python
plt.xlabel("yr_built")
plt.ylabel("price")
plt.scatter(x=df["yr_built"], y=df["price"])
```

![yrbyprice](yrbyprice.svg)


### Fitting the Model

First, let's organize our data into X, REPLACE, and y, what we're trying to predict (price, in our case).

```python
X = df.loc[:, ["sqft_living", "yr_built"]]
y = df.loc[:, "price"]
```

Now, let's use `scikit-learn` to perform linear regression (there's no need to write the code for this on our own):

```python
import sklearn.linear_model as lm

linear_model = lm.LinearRegression()
linear_model.fit(X, y)

print("""
intercept: %.2f
sqft_living: %.2f
yr_built: %.2f
""" % (tuple([linear_model.intercept_]) + tuple(linear_model.coef_)))
```

> intercept: 4545840.77

> sqft_living:    304.57

> yr_built:    -2353.73

Above are the (estimates of) coefficients we get from our linear regression model. Now, we want to bootstrap our observations. 

### Using Bootstrap

For the purposes of this tutorial, we can write a simple resampling function using [random integers generated by NumPy](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html?highlight=randint#numpy.random.randint) (note that these are not true random numbers): 
```python
def simple_resample(n): 
    return(np.random.randint(low = 0, high = n, size = n))
```

Now, let's write out a very general bootstrap function that takes in a bootstrap population (not the true population), some statistic, a resampling function (set default to our `simple_resample`), and the amount of replicates (set default to 10000):

```python
def bootstrap(boot_pop, statistic, resample = simple_resample, replicates = 10000):
    n = len(boot_pop)
    resample_estimates = np.array([statistic(boot_pop[resample(n)]) for _ in range(replicates)])
    return resample_estimates
```







<!-- Columns:

- `id`
- `date`
- `price`
- `bedrooms`
- `bathrooms`
- `sqft_living`
- `sqft_lot`
- `floors`
- `waterfront`
- `view`
- `condition`
- `grade`
- `sqft_above`
- `sqft_basement`
- `yr_built`
- `yr_renovated`
- `zipcode`
- `lat`
- `long`
- `sqft_living15`
- `sqft_lot15` -->


## Additional Resources
<!-- 
You can read more about bootstrapping [on Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_(statistics).) -->


## References